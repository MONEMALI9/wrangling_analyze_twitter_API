{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Wrangle Report\n",
    "\n",
    "### Dataset Description \n",
    "\n",
    "> **Tip**:Real-world data rarely comes clean. Using Python and its libraries, you will gather data from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. This is called data wrangling. You will document your wrangling efforts in a Jupyter Notebook, plus showcase them through analyses and visualizations using Python (and its libraries) and/or SQL.\n",
    "The dataset that you will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user [@dog_rates](https://twitter.com/dog_rates), also known as [WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs). WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because [\"they're good dogs Brent.\"](https://knowyourmeme.com/memes/theyre-good-dogs-brent) WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "WeRateDogs [downloaded their Twitter archive](https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive) and sent it to Udacity via email exclusively for you to use in this project. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017. More on this soon.. \n",
    "\n",
    "#### Your task is to:\n",
    "\n",
    "01 - Gathering data.\n",
    "\n",
    "02 - Assessing data.\n",
    "\n",
    "03 - Cleaning data.\n",
    "\n",
    "04 - Storing data.\n",
    "\n",
    "05 - Analyzing, and visualizing data.\n",
    "\n",
    "06 - Reporting\n",
    "\n",
    "        your data wrangling efforts\n",
    "        your data analyses and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. gathering each of pieces of data programmatically. \n",
    "\n",
    "> **Tip**:Each step will be further explained below The data used was gathered from three different sources :\n",
    "\n",
    "> **Tip**:A)Enhanced Twitter Archive Contains data extracted programmatically from tweet data sent by WeRate Dogs to Udacity via email exclusively to be used in this project . The data provides the rating , dog name , and dog stage and some other related information . This file was downloaded manually from the provided link and uploaded to the project work space . [twitter-archive- enhanced.csv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958).\n",
    "\n",
    "> **Tip**:B)Image Predictions File Produced by running every image in the WeRate Dogs Twitter archive through a neural network that classifies breeds of dogs . This process resulted in a table full of image predictions ( the top three only ) alongside each tweet ID , image URL , and the image number that corresponded to the most confident prediction ( numbered 1 to 4 since tweets can have up to four images ) . This file is hosted on Udacity's servers and was downloaded programmatically using the Requests library and the following URL : [image-predictions.tsv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd)\n",
    "\n",
    "> **Tip**:C)Additional Data via Twitter API Obtained by querying Twitter's API then stored in a txt file called tweet json . Gathering this data requires a Twitter developer account . Note : A ready - made version of the file is provided by Udacity for those who faced difficulties creating a Twitter developer account .\n",
    "The ready - made version was used in this work and was read line by line into a pandas DataFrame with tweet ID , retweet count , and favorite count , and was later saved to a ' tweet_data.csv ' file for future use ( without the index column so it will not appear as unnamed column in the file ) . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Assessing Data After gathering each of the above pieces of data , they were assessed visually and programmatically for quality and tidiness issues . \n",
    "\n",
    "The following findings were concluded ( Only the cleaned ones are mentioned ) :\n",
    "\n",
    "A)Tidiness : \n",
    "\n",
    "    T1. Dog stage data is separated into 4 columns. \n",
    "    T2. All data is related but divided into 3 separate dataframes.\n",
    "\n",
    "B)Quality : \n",
    "\n",
    "A. Enhanced Twitter Archive \n",
    "\n",
    "    Q1. There are 181 retweetes as indicated by retweeted_status_id. \n",
    "    Q2. Some dog names are invalid (None , a , an , & the instead of name).\n",
    "    Q3. Invalid tweet_id data type (integer instead of string). \n",
    "    Q4. Invalid timestamp data type (string not datetime). \n",
    "\n",
    "B. Tweet Image Predictions\n",
    "\n",
    "    Q1. Missing photos for some IDs (2075 rows instead of 2356). \n",
    "    Q2. Underscores are used in multi - word names in columns p1 , p2 , & p3 instead of spaces. \n",
    "    Q3. Some P names start with an uppercase letter while others start with lowercase.\n",
    "    \n",
    "B. Tweet Data from Twitter API\n",
    "\n",
    "    Q1. Missing entries (2345 entries instead of 2356). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data Cleansing\n",
    "\n",
    "    the previous issuses were cleaned as appropriateresulting in high quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
